{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- import spacy\n",
    "- nlp spacy.load\n",
    "- text, pos, dep\n",
    "- Tokenization\n",
    "- **entities**\n",
    "- noun chunks\n",
    "- displacy\n",
    "- **Stemmization**\n",
    "- porter\n",
    "- snowball\n",
    "- **Limmetization**\n",
    "- **Stop words** \n",
    "- add and remove from stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Today is the first day of learning Spacy, i am sure this is going to be fun. current time is 13:45 PM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Today is the first day of learning Spacy, i am sure this is going to be fun. current time is 13:45 PM"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today           NOUN      nsubj\n",
      "is           VERB      ccomp\n",
      "the           DET      det\n",
      "first           ADJ      amod\n",
      "day           NOUN      attr\n",
      "of           ADP      prep\n",
      "learning           VERB      pcomp\n",
      "Spacy           PROPN      dobj\n",
      ",           PUNCT      punct\n",
      "i           PRON      nsubj\n",
      "am           VERB      ROOT\n",
      "sure           ADJ      acomp\n",
      "this           DET      nsubj\n",
      "is           VERB      aux\n",
      "going           VERB      ccomp\n",
      "to           PART      aux\n",
      "be           VERB      xcomp\n",
      "fun           ADJ      acomp\n",
      ".           PUNCT      punct\n",
      "current           ADJ      amod\n",
      "time           NOUN      nsubj\n",
      "is           VERB      ROOT\n",
      "13:45           NUM      nummod\n",
      "PM           NOUN      attr\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,'         ',token.pos_, '    ', token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x219fe5025c8>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x219fe5011c8>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x219fe501768>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "\n",
    "\n",
    "![](tokenization.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystring = '\"we\\'re moving to U.S.A\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"we\\'re moving to U.S.A\"'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"we're moving to U.S.A\"\n"
     ]
    }
   ],
   "source": [
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "we\n",
      "'re\n",
      "moving\n",
      "to\n",
      "U.S.A\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'we\\'re here to help! send-email to us, email support@oursite.com or visit us http://www.oursite.com.!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "we're here to help! send-email to us, email support@oursite.com or visit us http://www.oursite.com.!"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "send\n",
      "-\n",
      "email\n",
      "to\n",
      "us\n",
      ",\n",
      "email\n",
      "support@oursite.com\n",
      "or\n",
      "visit\n",
      "us\n",
      "http://www.oursite.com\n",
      ".\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'a 5km NYC cab ride costs $10.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "5\n",
      "km\n",
      "NYC\n",
      "cab\n",
      "ride\n",
      "costs\n",
      "$\n",
      "10.3\n"
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u\"let's visit St. louis in the U.S next year.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let\n",
      "'s\n",
      "visit\n",
      "St.\n",
      "louis\n",
      "in\n",
      "the\n",
      "U.S\n",
      "next\n",
      "year\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc4:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57852"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc3.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5 = nlp(u'Apple to build a factory in Hong Kong wiht $6m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | factory | in | Hong | Kong | wiht | $ | 6 | m | "
     ]
    }
   ],
   "source": [
    "for token in doc5:\n",
    "    print(token, end=' | ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## special entity in whole statement(information). excluding the noun,pronoun and other POS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "ORG\n",
      "Companies, agencies, institutions, etc.\n",
      "\n",
      "\n",
      "Hong Kong\n",
      "GPE\n",
      "Countries, cities, states\n",
      "\n",
      "\n",
      "$6m\n",
      "MONEY\n",
      "Monetary values, including unit\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in doc5.ents:\n",
    "    print(t)\n",
    "    print(t.label_)\n",
    "    print((spacy.explain(t.label_)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "a factory\n",
      "Hong Kong\n",
      "$6m\n"
     ]
    }
   ],
   "source": [
    "for chunks in doc5.noun_chunks:\n",
    "    print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# displacy\n",
    "\n",
    "- dep\n",
    "- ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc6 = nlp(u'Apple to build a factory in Hong Kong wiht $6m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1490\" height=\"377.0\" style=\"max-width: none; height: 377.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">Hong</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">Kong</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">wiht</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">m</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,242.0 C70,2.0 1010.0,2.0 1010.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,244.0 L62,232.0 78,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M190,242.0 C190,182.0 275.0,182.0 275.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M190,244.0 L182,232.0 198,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M70,242.0 C70,122.0 280.0,122.0 280.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M280.0,244.0 L288.0,232.0 272.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M430,242.0 C430,182.0 515.0,182.0 515.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,244.0 L422,232.0 438,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M310,242.0 C310,122.0 520.0,122.0 520.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520.0,244.0 L528.0,232.0 512.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M550,242.0 C550,182.0 635.0,182.0 635.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M635.0,244.0 L643.0,232.0 627.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M790,242.0 C790,182.0 875.0,182.0 875.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,244.0 L782,232.0 798,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M670,242.0 C670,122.0 880.0,122.0 880.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880.0,244.0 L888.0,232.0 872.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M1150,242.0 C1150,182.0 1235.0,182.0 1235.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150,244.0 L1142,232.0 1158,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-9\" stroke-width=\"2px\" d=\"M1270,242.0 C1270,182.0 1355.0,182.0 1355.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-9\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270,244.0 L1262,232.0 1278,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-10\" stroke-width=\"2px\" d=\"M1030,242.0 C1030,62.0 1365.0,62.0 1365.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-10\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1365.0,244.0 L1373.0,232.0 1357.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc6,style = 'dep',jupyter=True,options={'distance':120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to build a factory in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hong Kong\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " wiht \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    $6m\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc6,style = 'ent',jupyter=True,options={'distance':120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Serving on port 5000...\u001b[0m\n",
      "    Using the 'dep' visualizer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Apr/2020 17:11:54] \"GET / HTTP/1.1\" 200 9095\n",
      "127.0.0.1 - - [16/Apr/2020 17:11:54] \"GET /favicon.ico HTTP/1.1\" 200 9095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Shutting down server on port 5000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displacy.serve(doc6,style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK = POrter and snowball stemmer\n",
    "\n",
    "stemmeing is not there in spacy.\n",
    "\n",
    "\n",
    "only nltk has it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','running','ran','easily','heavier','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run -----> run\n",
      "runner -----> runner\n",
      "running -----> run\n",
      "ran -----> ran\n",
      "easily -----> easili\n",
      "heavier -----> heavier\n",
      "fairly -----> fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word, '----->', p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run -----> run\n",
      "runner -----> runner\n",
      "running -----> run\n",
      "ran -----> ran\n",
      "easily -----> easili\n",
      "heavier -----> heavier\n",
      "fairly -----> fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word, '----->', s_stemmer.stem(word)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['generate','generous','generally','general','generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate -----> gener\n",
      "generous -----> gener\n",
      "generally -----> gener\n",
      "general -----> gener\n",
      "generation -----> gener\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word, '----->', p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate -----> generat\n",
      "generous -----> generous\n",
      "generally -----> general\n",
      "general -----> general\n",
      "generation -----> generat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word, '----->', s_stemmer.stem(word)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### snowball is better. It is visible in last example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Limmetization\n",
    "\n",
    "**Limmetization is beyond stemming, it just not only concentrate on reduction to its stem but it checks the complete vocab for related words.**\n",
    "\n",
    "lema for __'was'__ is __'be'__ and for __'mice'__ is __'mouse'__.**\n",
    "\n",
    "it varies as per the usage as well. so its quite intelligent in itself.\n",
    "\n",
    "e.g. 'meeting' could be 'meet' or 'meeting' itself depends on the usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc7 = nlp(u'I am a runner, running in marathon, i run frequently as i love running.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t -PRON-\n",
      "am \t VERB \t be\n",
      "a \t DET \t a\n",
      "runner \t NOUN \t runner\n",
      ", \t PUNCT \t ,\n",
      "running \t VERB \t run\n",
      "in \t ADP \t in\n",
      "marathon \t NOUN \t marathon\n",
      ", \t PUNCT \t ,\n",
      "i \t PRON \t i\n",
      "run \t VERB \t run\n",
      "frequently \t ADV \t frequently\n",
      "as \t ADP \t as\n",
      "i \t PRON \t i\n",
      "love \t VERB \t love\n",
      "running \t VERB \t run\n",
      ". \t PUNCT \t .\n"
     ]
    }
   ],
   "source": [
    "for t in doc7:\n",
    "    print(t.text , '\\t' , t.pos_ , '\\t' , t.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f string function for formattting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I          \t PRON                 \t -PRON-              \n",
      "am         \t VERB                 \t be                  \n",
      "a          \t DET                  \t a                   \n",
      "runner     \t NOUN                 \t runner              \n",
      ",          \t PUNCT                \t ,                   \n",
      "running    \t VERB                 \t run                 \n",
      "in         \t ADP                  \t in                  \n",
      "marathon   \t NOUN                 \t marathon            \n",
      ",          \t PUNCT                \t ,                   \n",
      "i          \t PRON                 \t i                   \n",
      "run        \t VERB                 \t run                 \n",
      "frequently \t ADV                  \t frequently          \n",
      "as         \t ADP                  \t as                  \n",
      "i          \t PRON                 \t i                   \n",
      "love       \t VERB                 \t love                \n",
      "running    \t VERB                 \t run                 \n",
      ".          \t PUNCT                \t .                   \n"
     ]
    }
   ],
   "source": [
    "for t in doc7:\n",
    "    print(f'{t.text:{10}} \\t {t.pos_:<{20}} \\t {t.lemma_:<{20}}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'say', 'during', 'please', 'forty', 'less', 'part', 'upon', 'whatever', 'if', 'about', 'somewhere', 'always', 'hereupon', 'below', 'former', 'more', 'same', 'toward', 'really', 'another', 'fifty', 'my', 'mostly', 'alone', 'much', 'one', 'own', 'nowhere', 'who', 'behind', 'again', 'for', 'besides', 'make', 'here', 'perhaps', 'there', 'whether', 'yet', 'otherwise', 'yours', 'many', 'namely', 'afterwards', 'side', 'he', 'due', 'therefore', 'a', 'on', 'at', 'them', 'twelve', 'also', 'almost', 'amount', 'does', 'ours', 'via', 'by', 'everywhere', 'into', 'whereafter', 'yourselves', 'move', 'too', 'last', 'latter', 'therein', 'himself', 'is', 'off', 'call', 'after', 'five', 'fifteen', 'so', 'hereby', 'anyway', 'none', 'not', 'over', 'third', 'just', 'show', 'where', 'among', 'in', 'being', 'we', 'whereas', 'whole', 'whoever', 'still', 'whose', 'even', 'along', 'its', 'they', 'above', 'two', 'unless', 'us', 'various', 'without', 'between', 'can', 'might', 'ever', 'up', 'why', 'whereupon', 'be', 'hereafter', 'wherein', 'herein', 'thereby', 'with', 'something', 'than', 'his', 'no', 'well', 'me', 'amongst', 'each', 'around', 'other', 'empty', 'thus', 'seem', 'nothing', 'nobody', 'moreover', 'hence', 'beforehand', 'everything', 'keep', 'every', 'meanwhile', 'through', 'using', 'across', 'thru', 'take', 'neither', 'could', 'did', 'had', 'should', 'this', 'whom', 'eleven', 'nine', 'several', 'give', 'it', 'sometime', 'next', 'such', 'our', 'until', 'however', 'within', 'but', 'anywhere', 'becomes', 'do', 'doing', 'go', 'now', 'serious', 'ten', 'how', 'you', 'ca', 'have', 'was', 'four', 'name', 'rather', 'anyone', 'then', 'that', 'cannot', 'their', 'though', 'and', 'of', 'ourselves', 'throughout', 'may', 'made', 'formerly', 'bottom', 'an', 'beside', 'put', 'others', 'per', 'those', 'eight', 'became', 'itself', 'what', 'front', 'never', 'everyone', 'becoming', 'once', 'become', 'latterly', 'except', 'myself', 'whereby', 'from', 'beyond', 'either', 'few', 'which', 'regarding', 'elsewhere', 'nor', 'under', 'nevertheless', 'onto', 'very', 'indeed', 'since', 'seems', 'anyhow', 'thence', 'three', 'hundred', 'before', 'to', 'him', 'mine', 'she', 'i', 'quite', 'enough', 'else', 'yourself', 'all', 'only', 'already', 'sixty', 'herself', 'somehow', 'seemed', 'as', 'back', 'get', 'together', 'out', 'were', 'wherever', 'six', 'would', 'thereupon', 're', 'used', 'someone', 'whither', 'seeming', 'whenever', 'will', 'twenty', 'towards', 'thereafter', 'sometimes', 'further', 'has', 'because', 'these', 'down', 'full', 'hers', 'whence', 'while', 'when', 'although', 'are', 'am', 'done', 'anything', 'noone', 'must', 'the', 'some', 'most', 'see', 'your', 'against', 'both', 'least', 'often', 'themselves', 'top', 'any', 'or', 'been', 'her', 'first'}\n",
      "\n",
      " 305\n"
     ]
    }
   ],
   "source": [
    "print((nlp.Defaults.stop_words))\n",
    "print('\\n',len(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['true'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['whether'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['btw'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.add('btw')\n",
    "nlp.vocab['btw'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['btw'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306\n"
     ]
    }
   ],
   "source": [
    "print(len(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.add('latter')\n",
    "nlp.vocab['latter'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['latter'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
